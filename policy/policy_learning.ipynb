{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71fe81dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import absl.logging\n",
    "\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "# 0 = all messages are logged (default behavior)\n",
    "# 1 = INFO messages are not printed\n",
    "# 2 = INFO and WARNING messages are not printed\n",
    "# 3 = INFO, WARNING, and ERROR messages are not printed\n",
    "\n",
    "# On Mac you may encounter an error related to OMP, this is a workaround, but slows down the code\n",
    "# https://github.com/dmlc/xgboost/issues/1715\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "132953ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43ca9a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device:/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "if tf.test.gpu_device_name():\n",
    "    print(\"Default GPU Device:{}\".format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF if you have one.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ac37fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device:/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "from openbot import dataloader, data_augmentation, utils, train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c28641",
   "metadata": {},
   "source": [
    "## Set train and test dirs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc941e8e",
   "metadata": {},
   "source": [
    "Define the dataset directory and give it a name. Inside the dataset folder, there should be two folders, `train_data` and `test_data`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "823ef8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"dataset\"\n",
    "dataset_name = \"openbot\"\n",
    "train_data_dir = os.path.join(dataset_dir, \"train_data\")\n",
    "test_data_dir = os.path.join(dataset_dir, \"test_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4388bbaa",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "<a id='hyperparameters'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625eb2bd",
   "metadata": {},
   "source": [
    "You may have to tune the learning rate and batch size depending on your available compute resources and dataset. As a general rule of thumb, if you increase the batch size by a factor of n, you can increase the learning rate by a factor of sqrt(n). In order to accelerate training and make it more smooth, you should increase the batch size as much as possible. In our paper we used a batch size of 128. For debugging and hyperparamter tuning, you can set the number of epochs to a small value like 10. If you want to train a model which will achieve good performance, you should set it to 50 or more. In our paper we used 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a14c7cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = train.Hyperparameters()\n",
    "\n",
    "params.MODEL = \"pilot_net\"  # choices: \"pilot_net\",\"cil_mobile\",\"cil_mobile_fast\",\"cil\"\n",
    "params.POLICY = \"autopilot\"  # choices: \"autopilot\",\"point_goal_nav\"\n",
    "params.TRAIN_BATCH_SIZE = 128\n",
    "params.TEST_BATCH_SIZE = 16\n",
    "params.LEARNING_RATE = 0.0003\n",
    "params.NUM_EPOCHS = 100\n",
    "params.BATCH_NORM = True  # use batch norm (recommended)\n",
    "params.FLIP_AUG = False  # flip image and controls as augmentation (only autopilot)\n",
    "params.CMD_AUG = False  # randomize high-level command as augmentation (only autopilot)\n",
    "params.USE_LAST = False  # resume training from last checkpoint\n",
    "params.WANDB = False\n",
    "# policy = \"autopilot\": images are expected to be 256x96 - no cropping required\n",
    "# policy = \"point_goal_nav\": images are expected to be 160x120 - cropping to 160x90\n",
    "params.IS_CROP = params.POLICY == \"point_goal_nav\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ac0929",
   "metadata": {},
   "source": [
    "## Pre-process the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b4494b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = train.Training(params)\n",
    "tr.dataset_name = dataset_name\n",
    "tr.train_data_dir = train_data_dir\n",
    "tr.test_data_dir = test_data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfc9b9b",
   "metadata": {},
   "source": [
    "Running this for the first time will take some time. This code will match image frames to the controls (labels) and indicator signals (commands).  By default, data samples where the vehicle was stationary will be removed. If this is not desired, you need to set `tr.remove_zeros = False`. If you have made any changes to the sensor files, changed `remove_zeros` or moved your dataset to a new directory, you need to set `tr.redo_matching = True`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9d78141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Datasets:  1\n",
      "Test Datasets:  1\n",
      "Processing folder dataset\\train_data\\my_dataset_1\\20231005_171424\n",
      " Frames and controls already matched.\n",
      " Frames and commands already matched.\n",
      " Preprocessing already completed.\n",
      "There are 72 train images and 0 test images\n"
     ]
    }
   ],
   "source": [
    "tr.redo_matching = False\n",
    "tr.remove_zeros = True\n",
    "train.process_data(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c531aecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "\n",
    "def broadcast(event, payload=None):\n",
    "    print(event, payload)\n",
    "\n",
    "\n",
    "event = threading.Event()\n",
    "my_callback = train.MyCallback(broadcast, event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc670c9",
   "metadata": {},
   "source": [
    "In the next step, you can convert your dataset to a tfrecord, a data format optimized for training. You can skip this step if you already created a tfrecord before or if you want to train using the files directly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59336936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "message Converting data to tfrecord (this may take some time)...\n",
      "Reading dataset from C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\n",
      "TFRecord will be saved at C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\tfrecords/train.tfrec\n",
      "Number of Datasets Available:  1\n",
      "Processing folder C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\n",
      " Frames and controls matched.\n",
      " Frames and high-level commands matched.\n",
      " Preprocessing completed.\n",
      "87115168670776,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\599_crop.jpeg,98,106,0\n",
      "87115349883797,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\600_crop.jpeg,98,106,0\n",
      "87115542468015,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\601_crop.jpeg,98,106,0\n",
      "87115749161817,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\602_crop.jpeg,98,106,0\n",
      "87115861466557,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\603_crop.jpeg,98,106,0\n",
      "87115972490567,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\604_crop.jpeg,98,106,0\n",
      "87116056890567,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\605_crop.jpeg,98,106,0\n",
      "87116129709265,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\606_crop.jpeg,98,106,0\n",
      "87116280820463,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\607_crop.jpeg,98,106,0\n",
      "87116387954994,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\608_crop.jpeg,98,106,0\n",
      "87116477708432,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\609_crop.jpeg,98,106,0\n",
      "87116567070254,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\610_crop.jpeg,98,106,0\n",
      "87116666602963,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\611_crop.jpeg,98,106,0\n",
      "87116752504890,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\612_crop.jpeg,98,106,0\n",
      "87116832406400,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\613_crop.jpeg,98,106,0\n",
      "87116914502963,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\614_crop.jpeg,98,106,0\n",
      "87117006608431,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\615_crop.jpeg,98,106,0\n",
      "87117090180827,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\616_crop.jpeg,98,106,0\n",
      "87117194671452,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\617_crop.jpeg,98,106,0\n",
      "87117260514629,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\618_crop.jpeg,98,106,0\n",
      "87117342554369,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\619_crop.jpeg,98,106,0\n",
      "87117419462337,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\620_crop.jpeg,98,106,0\n",
      "87117474185410,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\621_crop.jpeg,98,106,0\n",
      "87117575522962,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\622_crop.jpeg,98,106,0\n",
      "87117653806712,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\623_crop.jpeg,98,106,0\n",
      "87117732982389,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\624_crop.jpeg,98,106,0\n",
      "87117853538483,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\625_crop.jpeg,98,106,0\n",
      "87117924686556,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\626_crop.jpeg,98,106,0\n",
      "87118062001868,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\627_crop.jpeg,98,106,0\n",
      "87118188680723,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\628_crop.jpeg,98,106,0\n",
      "87118264447545,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\629_crop.jpeg,98,106,0\n",
      "87118341325150,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\630_crop.jpeg,98,106,0\n",
      "87118427068847,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\631_crop.jpeg,98,106,0\n",
      "87118511234316,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\632_crop.jpeg,98,106,0\n",
      "87118590286295,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\633_crop.jpeg,98,106,0\n",
      "87118665007754,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\634_crop.jpeg,98,106,0\n",
      "87118744933379,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\635_crop.jpeg,98,106,0\n",
      "87118838120462,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\636_crop.jpeg,98,106,0\n",
      "87118924656243,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\637_crop.jpeg,98,106,0\n",
      "87119009539837,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\638_crop.jpeg,98,106,0\n",
      "87119131356399,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\639_crop.jpeg,98,106,0\n",
      "87119265223274,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\640_crop.jpeg,98,106,0\n",
      "87119359984889,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\641_crop.jpeg,98,106,0\n",
      "87119458878691,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\642_crop.jpeg,98,106,0\n",
      "87119691938378,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\643_crop.jpeg,98,106,0\n",
      "87119825976034,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\644_crop.jpeg,98,106,0\n",
      "87119995960305,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\645_crop.jpeg,98,106,0\n",
      "87120129313274,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\646_crop.jpeg,98,106,0\n",
      "87120247067961,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\647_crop.jpeg,98,106,0\n",
      "87120343860461,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\648_crop.jpeg,98,106,0\n",
      "87120455288117,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\649_crop.jpeg,98,106,0\n",
      "87120529305357,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\650_crop.jpeg,98,106,0\n",
      "87120628117440,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\651_crop.jpeg,98,106,0\n",
      "87120721584263,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\652_crop.jpeg,98,106,0\n",
      "87120830597805,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\653_crop.jpeg,98,106,0\n",
      "87120919204211,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\654_crop.jpeg,98,106,0\n",
      "87121014504732,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\655_crop.jpeg,98,106,0\n",
      "87121094455826,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\656_crop.jpeg,98,106,0\n",
      "87121166563169,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\657_crop.jpeg,98,106,0\n",
      "87121266653951,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\658_crop.jpeg,98,106,0\n",
      "87121343506346,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\659_crop.jpeg,98,106,0\n",
      "87121469243742,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\660_crop.jpeg,98,106,0\n",
      "87121560576815,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\661_crop.jpeg,98,106,0\n",
      "87121664357127,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\662_crop.jpeg,98,106,0\n",
      "87121752764575,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\663_crop.jpeg,98,106,0\n",
      "87121845237909,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\664_crop.jpeg,98,106,0\n",
      "87121972079419,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\665_crop.jpeg,98,106,0\n",
      "87122076700513,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\666_crop.jpeg,98,106,0\n",
      "87122267043950,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\667_crop.jpeg,98,106,0\n",
      "87122385469575,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\668_crop.jpeg,98,106,0\n",
      "87122503301033,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\669_crop.jpeg,98,106,0\n",
      "87122622339835,C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\train_data\\my_dataset_1\\20231005_171424\\images\\670_crop.jpeg,98,106,0\n",
      "\n",
      "Oops! Image C:/Users/lilou/Documents/Master's cannot be found.\n",
      "TFRecord file created successfully.\n",
      "Reading dataset from C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\test_data\n",
      "TFRecord will be saved at C:\\Users\\lilou\\Documents\\Master's research\\OpenBot\\policy\\dataset\\tfrecords/test.tfrec\n",
      "Number of Datasets Available:  1\n",
      "TFRecord file created successfully.\n"
     ]
    }
   ],
   "source": [
    "train.create_tfrecord(my_callback, policy=tr.hyperparameters.POLICY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a4a1cf",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51ee383",
   "metadata": {},
   "source": [
    "If you did not create a tfrecord and want to load and buffer files from disk directly, set `no_tf_record = True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc2d2068",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_tf_record = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "082c90bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training instances:  0\n",
      "Number of test instances:  0\n"
     ]
    }
   ],
   "source": [
    "if no_tf_record:\n",
    "    tr.train_data_dir = train_data_dir\n",
    "    tr.test_data_dir = test_data_dir\n",
    "    train.load_data(tr, verbose=0)\n",
    "else:\n",
    "    tr.train_data_dir = os.path.join(dataset_dir, \"tfrecords/train.tfrec\")\n",
    "    tr.test_data_dir = os.path.join(dataset_dir, \"tfrecords/test.tfrec\")\n",
    "    train.load_tfrecord(tr, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "edf34f3f",
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\openbot\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:766\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 766\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\openbot\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:749\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[1;32m--> 749\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    750\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    752\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    754\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    755\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\openbot\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3016\u001b[0m, in \u001b[0;36miterator_get_next\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   3015\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 3016\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3017\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\openbot\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7164\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7163\u001b[0m e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 7164\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[1;31mOutOfRangeError\u001b[0m: End of sequence [Op:IteratorGetNext]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhyperparameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPOLICY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\Master's research\\OpenBot\\policy\\openbot\\utils.py:53\u001b[0m, in \u001b[0;36mshow_batch\u001b[1;34m(dataset, policy, model, fig_num)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow_batch\u001b[39m(dataset, policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mautopilot\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, fig_num\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 53\u001b[0m     (image_batch, cmd_batch), label_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m     NUM_SAMPLES \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(image_batch\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m15\u001b[39m)\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m policy \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mautopilot\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\openbot\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:768\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    766\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_internal()\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[1;32m--> 768\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "utils.show_batch(dataset=tr.train_ds, policy=tr.hyperparameters.POLICY, model=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5d0f77",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71034420",
   "metadata": {},
   "source": [
    "The number of epochs is proportional to the training time. One epoch means going through the complete dataset once. Increasing `NUM_EPOCHS` will mean longer training time, but generally leads to better performance. To get familiar with the code it can be set to small values like `5` or `10`. To train a model that performs well, it should be set to values between `50` and `200`. Setting `USE_LAST` to `true` will resume the training from the last checkpoint. The default values are `NUM_EPOCHS = 100` and `USE_LAST = False`. They are set in [Hyperparameters](#hyperparameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "894cd54f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "One of the dimensions in the output is <= 0 due to downsampling in conv2d. Consider increasing the input size. Received input shape [None, 0, 0, 3] which would produce output shape with a zero or negative value in a dimension.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# params.NUM_EPOCHS = 200\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# params.USE_LAST = True\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmy_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\Master's research\\OpenBot\\policy\\openbot\\train.py:430\u001b[0m, in \u001b[0;36mdo_training\u001b[1;34m(tr, callback, verbose)\u001b[0m\n\u001b[0;32m    427\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m    429\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m resume_training:\n\u001b[1;32m--> 430\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhyperparameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMODEL\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNETWORK_IMG_WIDTH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNETWORK_IMG_HEIGHT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhyperparameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBATCH_NORM\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhyperparameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPOLICY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    436\u001b[0m     dot_img_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(models_dir, tr\u001b[38;5;241m.\u001b[39mmodel_name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    437\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mplot_model(model, to_file\u001b[38;5;241m=\u001b[39mdot_img_file, show_shapes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\Documents\\Master's research\\OpenBot\\policy\\openbot\\models.py:86\u001b[0m, in \u001b[0;36mpilot_net\u001b[1;34m(img_width, img_height, bn, policy)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown policy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 86\u001b[0m cnn \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_cnn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimg_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimg_height\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcnn_filters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m36\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m48\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel_sz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmlp_filters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1164\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmlp_dropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# fuse input MLP and CNN\u001b[39;00m\n\u001b[0;32m    101\u001b[0m combinedInput \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mconcatenate([mlp\u001b[38;5;241m.\u001b[39moutput, cnn\u001b[38;5;241m.\u001b[39moutput])\n",
      "File \u001b[1;32m~\\Documents\\Master's research\\OpenBot\\policy\\openbot\\models.py:36\u001b[0m, in \u001b[0;36mcreate_cnn\u001b[1;34m(width, height, depth, cnn_filters, kernel_sz, stride, padding, activation, conv_dropout, mlp_filters, mlp_dropout, bn)\u001b[0m\n\u001b[0;32m     33\u001b[0m     x \u001b[38;5;241m=\u001b[39m inputs\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# build one block with conv, activation and optional bn and dropout\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConv2D\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mkernel_sz\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_sz\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mactivation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bn:\n\u001b[0;32m     44\u001b[0m     x \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mBatchNormalization(axis\u001b[38;5;241m=\u001b[39mchannelDim)(x)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\openbot\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\openbot\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py:307\u001b[0m, in \u001b[0;36mConv.compute_output_shape\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mTensorShape(\n\u001b[0;32m    303\u001b[0m         input_shape[:batch_rank] \u001b[38;5;241m+\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilters] \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m    304\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spatial_output_shape(input_shape[batch_rank \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m:]))\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m--> 307\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    308\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOne of the dimensions in the output is <= 0 \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    309\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdue to downsampling in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Consider \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    310\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mincreasing the input size. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    311\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReceived input shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m which would produce \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    312\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput shape with a zero or negative value in a \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    313\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdimension.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: One of the dimensions in the output is <= 0 due to downsampling in conv2d. Consider increasing the input size. Received input shape [None, 0, 0, 3] which would produce output shape with a zero or negative value in a dimension."
     ]
    }
   ],
   "source": [
    "# params.NUM_EPOCHS = 200\n",
    "# params.USE_LAST = True\n",
    "train.do_training(tr, my_callback, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfd4aac",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f623b65f",
   "metadata": {},
   "source": [
    "The loss and mean absolute error should decrease. This indicates that the model is fitting the data well. The custom metrics (direction and angle) should go towards 1. These provide some additional insight to the training progress. The direction metric measures weather or not predictions are in the same direction as the labels. Similarly the angle metric measures if the prediction is within a small angle of the labels. The intuition is that driving in the right direction with the correct steering angle is most critical part for good final performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4867aaa7",
   "metadata": {},
   "source": [
    "### Plot metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca0b291",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(tr.INITIAL_EPOCH + 1, tr.history.params[\"epochs\"] + 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd65e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure().gca().xaxis.get_major_locator().set_params(integer=True)\n",
    "plt.plot(x, tr.history.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(x, tr.history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.savefig(os.path.join(tr.log_path, \"loss.png\"), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e98f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure().gca().xaxis.get_major_locator().set_params(integer=True)\n",
    "plt.plot(x, tr.history.history[\"mean_absolute_error\"], label=\"mean_absolute_error\")\n",
    "plt.plot(\n",
    "    x, tr.history.history[\"val_mean_absolute_error\"], label=\"val_mean_absolute_error\"\n",
    ")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Mean Absolute Error\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.savefig(os.path.join(tr.log_path, \"error.png\"), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1752d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure().gca().xaxis.get_major_locator().set_params(integer=True)\n",
    "plt.plot(x, tr.history.history[\"direction_metric\"], label=\"direction_metric\")\n",
    "plt.plot(x, tr.history.history[\"val_direction_metric\"], label=\"val_direction_metric\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Direction Metric\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(os.path.join(tr.log_path, \"direction.png\"), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de04eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure().gca().xaxis.get_major_locator().set_params(integer=True)\n",
    "plt.plot(x, tr.history.history[\"angle_metric\"], label=\"angle_metric\")\n",
    "plt.plot(x, tr.history.history[\"val_angle_metric\"], label=\"val_angle_metric\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Angle Metric\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(os.path.join(tr.log_path, \"angle.png\"), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72c1de3",
   "metadata": {},
   "source": [
    "### Save tf lite models for best train, best val and last checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a1ef62",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_train_checkpoint = \"cp-best-train.ckpt\"\n",
    "best_train_tflite = utils.generate_tflite(tr.checkpoint_path, best_train_checkpoint)\n",
    "utils.save_tflite(best_train_tflite, tr.checkpoint_path, \"best-train\")\n",
    "best_train_index = np.argmin(np.array(tr.history.history[\"loss\"]))\n",
    "print(\n",
    "    \"Best Train Checkpoint (epoch %s) - angle: %.4f, val_angle: %.4f, direction: %.4f, val_direction: %.4f\"\n",
    "    % (\n",
    "        best_train_index,\n",
    "        tr.history.history[\"angle_metric\"][best_train_index],\n",
    "        tr.history.history[\"val_angle_metric\"][best_train_index],\n",
    "        tr.history.history[\"direction_metric\"][best_train_index],\n",
    "        tr.history.history[\"val_direction_metric\"][best_train_index],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb605b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_checkpoint = \"cp-best-val.ckpt\"\n",
    "best_val_tflite = utils.generate_tflite(tr.checkpoint_path, best_val_checkpoint)\n",
    "utils.save_tflite(best_val_tflite, tr.checkpoint_path, \"best\")\n",
    "utils.save_tflite(best_val_tflite, tr.checkpoint_path, \"best-val\")\n",
    "best_val_index = np.argmin(np.array(tr.history.history[\"val_loss\"]))\n",
    "print(\n",
    "    \"Best Val Checkpoint (epoch %s) - angle: %.4f, val_angle: %.4f, direction: %.4f, val_direction: %.4f\"\n",
    "    % (\n",
    "        best_val_index,\n",
    "        tr.history.history[\"angle_metric\"][best_val_index],\n",
    "        tr.history.history[\"val_angle_metric\"][best_val_index],\n",
    "        tr.history.history[\"direction_metric\"][best_val_index],\n",
    "        tr.history.history[\"val_direction_metric\"][best_val_index],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2b1644",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_checkpoint = \"cp-last.ckpt\"\n",
    "last_tflite = utils.generate_tflite(tr.checkpoint_path, last_checkpoint)\n",
    "utils.save_tflite(last_tflite, tr.checkpoint_path, \"last\")\n",
    "print(\n",
    "    \"Last Checkpoint - angle: %.4f, val_angle: %.4f, direction: %.4f, val_direction: %.4f\"\n",
    "    % (\n",
    "        tr.history.history[\"angle_metric\"][-1],\n",
    "        tr.history.history[\"val_angle_metric\"][-1],\n",
    "        tr.history.history[\"direction_metric\"][-1],\n",
    "        tr.history.history[\"val_direction_metric\"][-1],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c57018",
   "metadata": {},
   "source": [
    "### Evaluate the best model (train loss) on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a03c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_train_model = utils.load_model(\n",
    "    os.path.join(tr.checkpoint_path, best_train_checkpoint),\n",
    "    tr.loss_fn,\n",
    "    tr.metric_list,\n",
    "    tr.custom_objects,\n",
    ")\n",
    "loss, mae, direction, angle = best_train_model.evaluate(\n",
    "    tr.train_ds,\n",
    "    steps=tr.image_count_train / tr.hyperparameters.TRAIN_BATCH_SIZE,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92462709",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.show_batch(\n",
    "    dataset=tr.train_ds, policy=tr.hyperparameters.POLICY, model=best_train_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a078b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.compare_tf_tflite(best_train_model, best_train_tflite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ad2605",
   "metadata": {},
   "source": [
    "### Evaluate the best model (val loss) on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ac5b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_model = utils.load_model(\n",
    "    os.path.join(tr.checkpoint_path, best_val_checkpoint),\n",
    "    tr.loss_fn,\n",
    "    tr.metric_list,\n",
    "    tr.custom_objects,\n",
    ")\n",
    "loss, mae, direction, angle = best_val_model.evaluate(\n",
    "    tr.test_ds,\n",
    "    steps=tr.image_count_test / tr.hyperparameters.TEST_BATCH_SIZE,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e01e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.show_batch(\n",
    "    dataset=tr.test_ds, policy=tr.hyperparameters.POLICY, model=best_val_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf9dbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.compare_tf_tflite(best_val_model, best_val_tflite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c9d606",
   "metadata": {},
   "source": [
    "## Save the notebook as HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c47915f",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.save_notebook()\n",
    "current_file = \"policy_learning.ipynb\"\n",
    "output_file = os.path.join(tr.log_path, \"notebook.html\")\n",
    "utils.output_HTML(current_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa902ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
